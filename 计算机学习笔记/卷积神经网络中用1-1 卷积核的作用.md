# [卷积神经网络中用1*1 卷积核的作用](https://www.zhihu.com/question/56024942)
**linbin**
标签（空格分隔）： 卷积神经网络 


---

### 优点： 
1. 可以降低特征图的维数，防止参数过多，有利于增加深层网络的宽度
2. 增加模型深度，一定程度上提升模型的表征能


----------

### Inception
下图是Inception的结构，尽管也有不同的版本，但是其动机都是一样的下图是Inception的结构，尽管也有不同的版本，但是其动机都是一样的: 消除尺寸对于识别结果的影响，一次性使用多个不同filter size来抓取多个范围不同的概念，并让网络自己选择需要的特征。你也一定注意到了蓝色的1x1卷积，撇开它，先看左边的这个结构。输入（可以是被卷积完的长方体输出作为该层的输入）进来后，通常我们可以选择直接使用像素信息(1x1卷积)传递到下一层，可以选择3x3卷积，可以选择5x5卷积，还可以选择max pooling的方方式downsample刚被卷积后的feature maps。 但在实际的网络设计中，究竟该如何选择需要大量的实验和经验的。 Inception就不用我们来选择，而是将4个选项给神经网络，让网络自己去选择最合适的解决方案。接下来我们再看右边的这个结构，多了很多蓝色的1x1卷积。这些1x1卷积的作用是为了让网络根据需要能够更灵活的控制数据的depth的。

![inception_conv_1 采用极简图床上传](https://ws1.sinaimg.cn/large/79051d19ly1fr53y1dqvdj20rb08nq6z.jpg)
### 1x1卷积核
如果卷积的输出输入都只是一个平面，那么1x1卷积核并没有什么意义，它是完全不考虑像素与周边其他像素关系。 但卷积的输出输入是长方体，所以1x1卷积实际上是对每个像素点，在不同的channels上进行线性组合（信息整合），且保留了图片的原有平面结构，调控depth，从而完成升维或降维的功能。如下图所示，如果选择2个filters的1x1卷积层，那么数据就从原本的depth 3 降到了2。若用4个filters，则起到了升维的作用。
这就是为什么上面Inception的4个选择中都混合一个1x1卷积，如右侧所展示的那样。 其中，绿色的1x1卷积本身就1x1卷积，所以不需要再用另一个1x1卷积。 而max pooling用来去掉卷积得到的Feature Map中的冗余信息，所以出现在1x1卷积之前，紧随刚被卷积后的feature maps。
 
![]( https://ws1.sinaimg.cn/large/79051d19ly1fr549cff44j20hv0edtaj.jpg)


<img width="150" height="150" src="https://img-blog.csdn.net/20161028230559575"/>




